{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etesys/numerai/blob/main/kcwanglucky_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numerapi\n",
        "!pip install halo\n",
        "!git clone https://github.com/etesys/numerai\n",
        "%load numerai/utils.py"
      ],
      "metadata": {
        "id": "LMhSqp1QtzWJ",
        "outputId": "f8a68e6b-d449-4d1f-b52c-0dcb82545eac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numerapi in /usr/local/lib/python3.7/dist-packages (2.9.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from numerapi) (2018.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from numerapi) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.23.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from numerapi) (7.1.2)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from numerapi) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->numerapi) (1.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->numerapi) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (1.24.3)\n",
            "Requirement already satisfied: halo in /usr/local/lib/python3.7/dist-packages (0.0.31)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from halo) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from halo) (1.1.0)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from halo) (0.4.4)\n",
            "Requirement already satisfied: spinners>=0.0.24 in /usr/local/lib/python3.7/dist-packages (from halo) (0.0.24)\n",
            "Requirement already satisfied: log-symbols>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from halo) (0.0.14)\n",
            "fatal: destination path 'numerai' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d6y_eVlcssiT"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import gc\n",
        "import json\n",
        "from halo import Halo\n",
        "from numerapi import NumerAPI\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Cv5lEzOLssiX"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "from utils import (\n",
        "    save_model,\n",
        "    load_model,\n",
        "    neutralize,\n",
        "    get_biggest_change_features,\n",
        "    validation_metrics,\n",
        "    get_time_series_cross_val_splits,\n",
        "    save_model_config,\n",
        "    load_model_config,\n",
        "    ERA_COL,\n",
        "    DATA_TYPE_COL,\n",
        "    TARGET_COL,\n",
        "    EXAMPLE_PREDS_COL\n",
        ")\n",
        "\"\"\"\n",
        "napi = NumerAPI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rZbqzhsssiZ"
      },
      "source": [
        "## All training and model configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VwlyQcdYssib"
      },
      "outputs": [],
      "source": [
        "model_configs = {\n",
        "    \"LGBM_cfg1\": {\n",
        "        \"n_estimators\": 2000,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"max_depth\": 5,\n",
        "        \"num_leaves\": 2 ** 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "    \"LGBM_cfg2\": {\n",
        "        \"n_estimators\": 3000,\n",
        "        \"learning_rate\": 0.005,\n",
        "        \"max_depth\": 5,\n",
        "        \"num_leaves\": 2 ** 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "    \"RF_cfg1\": {\n",
        "        \"n_estimators\": 1000,\n",
        "        \"criterion\": \"squared_error\",\n",
        "        \"max_depth\": 5,\n",
        "        \"min_samples_leaf\": 5\n",
        "    },\n",
        "    \"RF_cfg2\": {\n",
        "        \"n_estimators\": 2000,\n",
        "        \"criterion\": \"squared_error\",\n",
        "        \"max_depth\": 3,\n",
        "        \"min_samples_leaf\": 5\n",
        "    },\n",
        "    \"XGB_cfg1\": {\n",
        "        \"n_estimators\": 2000,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"max_depth\": 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "    \"RF_cfg2\": {\n",
        "        \"n_estimators\": 3000,\n",
        "        \"learning_rate\": 0.005,\n",
        "        \"max_depth\": 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7N0XjmB-ssid"
      },
      "outputs": [],
      "source": [
        "training_configs = {\n",
        "    \"FEATURE_SET\": \"medium\",\n",
        "    \"MODEL_CONFIG\": \"LGBM_cfg1\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b5om9Qmzssie"
      },
      "outputs": [],
      "source": [
        "current_round = napi.get_current_round(tournament=8)  # tournament 8 is the primary Numerai Tournament\n",
        "# napi.download_dataset(\"numerai_tournament_data.parquet\", f\"data/tournament_data_{current_round}.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Zg-TqaFdssie"
      },
      "outputs": [],
      "source": [
        "spinner = Halo(text='', spinner='dots')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg0PKf14ssif"
      },
      "source": [
        "## Feature set information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "X0puYvDissig",
        "outputId": "6ecdb15c-904a-4ce7-e8ca-b08b929a0e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-593f7660d22d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/features.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfeature_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/features.json'"
          ]
        }
      ],
      "source": [
        "with open(\"data/features.json\", \"r\") as f:\n",
        "    feature_metadata = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4xIVBEZssig"
      },
      "outputs": [],
      "source": [
        "feature_set = training_configs[\"FEATURE_SET\"]\n",
        "features = feature_metadata[\"feature_sets\"][feature_set]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFw1dwq9ssih"
      },
      "outputs": [],
      "source": [
        "feature_metadata[\"feature_sets\"].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIjPU8zissii"
      },
      "outputs": [],
      "source": [
        "len(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdZyU6tLssii"
      },
      "outputs": [],
      "source": [
        "# read in just those features along with era and target columns\n",
        "read_columns = features + [ERA_COL, DATA_TYPE_COL, TARGET_COL]\n",
        "training_data = pd.read_parquet('data/numerai_training_data.parquet', columns=read_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s85vXDdbssij"
      },
      "outputs": [],
      "source": [
        "training_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNte1Z3Xssij"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_iuZCpQssik"
      },
      "source": [
        "## Correlation check: Avoid substitution effects\n",
        "If correlation between a pair of features is too high, then remove one of them. Use data at era0001 to check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg8sBRHrssik"
      },
      "outputs": [],
      "source": [
        "feature_corrs = training_data[training_data.era=='0574'][features].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDHKFcmVssik"
      },
      "outputs": [],
      "source": [
        "tdf = feature_corrs.stack()\n",
        "tdf = tdf[tdf.index.get_level_values(0) < tdf.index.get_level_values(1)]\n",
        "tdf.sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXgO70QUssil"
      },
      "outputs": [],
      "source": [
        "highly_correlated_cols = [col1 for col1, _ in tdf[(tdf>0.8) | (tdf<-0.8)].index.values]\n",
        "highly_correlated_cols = list(set(highly_correlated_cols))\n",
        "len(highly_correlated_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na-cZAeJssil"
      },
      "outputs": [],
      "source": [
        "# Remove 245 features that is highly correlated\n",
        "transformed_data = training_data.loc[:, ~training_data.columns.isin(highly_correlated_cols)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTkUh_s6ssim"
      },
      "outputs": [],
      "source": [
        "transformed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgFw0Hunssim"
      },
      "outputs": [],
      "source": [
        "uncorrelated_feats = [feat for feat in features if feat not in set(highly_correlated_cols)]\n",
        "len(uncorrelated_feats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2e19phNssim"
      },
      "source": [
        "## Stationarity check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPb7SJmossin"
      },
      "source": [
        "Do the stationarity check on correlation between features across eras. If the correlation of a feature pairs shows nonstationarity, log transform it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q50mxbOlssin"
      },
      "outputs": [],
      "source": [
        "feature_corrs = transformed_data[transformed_data.era=='0002'][uncorrelated_feats + [TARGET_COL]].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKeawC-6ssin"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "plt.imshow(feature_corrs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2WRjBuessin"
      },
      "outputs": [],
      "source": [
        "data_by_era = []\n",
        "for era in range(1, 575):\n",
        "    data_by_era.append(transformed_data.groupby(\"era\").get_group(\"{0:04d}\".format(era)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQfkSO96ssio"
      },
      "outputs": [],
      "source": [
        "corrs_by_era = []\n",
        "for i in range(len(data_by_era)):\n",
        "    corrs_by_era.append(data_by_era[i][uncorrelated_feats + [TARGET_COL]].corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLfLDq9Zssio"
      },
      "outputs": [],
      "source": [
        "len(corrs_by_era)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnumToZgssio"
      },
      "outputs": [],
      "source": [
        "all_cols = corrs_by_era[0].columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33uLl5xussio"
      },
      "outputs": [],
      "source": [
        "len(all_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXvvUWRNssio"
      },
      "outputs": [],
      "source": [
        "# non_stationary_pairs = []\n",
        "stationary_cols = collections.defaultdict(int)\n",
        "# pairs_cols = features + [TARGET_COL]\n",
        "for feat_i in range(len(all_cols)):\n",
        "    for feat_j in range(feat_i + 1, len(all_cols)):\n",
        "        # print(all_cols[feat_i], all_cols[feat_j])\n",
        "        series = [era_corrs.iloc[feat_i, feat_j] for era_corrs in corrs_by_era]\n",
        "        result = adfuller(series)\n",
        "        p_value = result[1]\n",
        "        if p_value > 0.05:\n",
        "            stationary_cols[all_cols[feat_i]] += 1\n",
        "            stationary_cols[all_cols[feat_j]] += 1\n",
        "            # non_stationary_pairs.append((all_cols[feat_i], all_cols[feat_j]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu7g0h9Vssip"
      },
      "outputs": [],
      "source": [
        "# Look at how many times a feature involves in a nonstationary pair in terms of correlation\n",
        "sorted([(stationary_cols[k], k) for k in stationary_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKurJ2sOssip"
      },
      "outputs": [],
      "source": [
        "len(sorted([(stationary_cols[k], k) for k in stationary_cols]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SG_VtcVssip"
      },
      "outputs": [],
      "source": [
        "len(all_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3GviSYNssip"
      },
      "outputs": [],
      "source": [
        "# Most features involve in multiple nonstationary pairs -> log transform the features\n",
        "for col in stationary_cols:\n",
        "    transformed_data[col] = np.log(transformed_data[col] + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4et0iKAlssiq"
      },
      "outputs": [],
      "source": [
        "transformed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeaLzVu_ssiq"
      },
      "outputs": [],
      "source": [
        "transformed_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWInHi8Pssiq"
      },
      "source": [
        "## Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay9ODhvMssiq"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components = 0.95)      # to explain 95% of variance\n",
        "numerical_data = transformed_data.loc[:, ~transformed_data.columns.isin([\"data_type\", \"target_nomi_20\"])]\n",
        "pca.fit(numerical_data)\n",
        "reduced_data = pca.transform(numerical_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J86d9M_Xssiq"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCgcMEJ5ssir"
      },
      "outputs": [],
      "source": [
        "model_clf_configs = {\n",
        "    \"LGBM_cfg1\": {\n",
        "        \"n_estimators\": 2000,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"max_depth\": 5,\n",
        "        \"num_leaves\": 2 ** 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "    \"LGBM_cfg2\": {\n",
        "        \"n_estimators\": 3000,\n",
        "        \"learning_rate\": 0.005,\n",
        "        \"max_depth\": 5,\n",
        "        \"num_leaves\": 2 ** 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "    \"RF_bl\": {\n",
        "        \"max_features\": 1,\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-lPjwa7ssir"
      },
      "source": [
        "### MDA analysis with Baseline Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKSTV7Fjssir"
      },
      "outputs": [],
      "source": [
        "model_clf_config = \"RF_bl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apTMcxJTssir"
      },
      "outputs": [],
      "source": [
        "def MDA(X, y, k):\n",
        "    cv = StratifiedKFold(n_splits=k, random_state=1, shuffle=True)\n",
        "\n",
        "    aucs, accs = [], []\n",
        "    clf = RandomForestClassifier(**model_clf_configs[\"RF_bl\"])\n",
        "    result = pd.DataFrame(columns=X.columns)\n",
        "    accs = pd.Series()\n",
        "        \n",
        "    for (train, test), i in zip(cv.split(X, y), range(k)):\n",
        "        clf.fit(X.iloc[train], y.iloc[train])\n",
        "        y_pred = clf.predict(X.iloc[test])\n",
        "\n",
        "        acc = accuracy_score(y.iloc[test], y_pred)\n",
        "        accs.loc[i] = acc\n",
        "\n",
        "        X_test = X.iloc[test].copy(deep=True)\n",
        "        for j in X.columns:\n",
        "            np.random.shuffle(X_test[j].values) # permutation of a single column \n",
        "            \n",
        "            pred = clf.predict(X_test) \n",
        "            result.loc[i, j] = accuracy_score(y.iloc[test], pred)\n",
        "\n",
        "    return accs, result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcwbO-6gssir"
      },
      "outputs": [],
      "source": [
        "X = transformed_data.filter(like='feature_', axis='columns')\n",
        "y = transformed_data[TARGET_COL].values.reshape(-1, 1)\n",
        "# ohe = OneHotEncoder()\n",
        "le = LabelEncoder()\n",
        "# y = ohe.fit_transform(y).toarray()\n",
        "y = pd.Series(le.fit_transform(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI98Fo9hssis"
      },
      "outputs": [],
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muF_4cPEssis"
      },
      "outputs": [],
      "source": [
        "accs, result = MDA(X, y, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_ZHeFJGssit"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNMTys-Nssit"
      },
      "outputs": [],
      "source": [
        "imp = (-result).add(accs, axis=0)\n",
        "imp = imp/(1.-result)\n",
        "imp = pd.concat({'mean':imp.mean(),'std':imp.std() * imp.shape[0] ** -.5}, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcWE2w2Hssit"
      },
      "outputs": [],
      "source": [
        "imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmy3vQHbssit"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9DlUg11ssit"
      },
      "source": [
        "## Train Regression models (LGBM, RF, XGBOOST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MelUcvTQssiu"
      },
      "outputs": [],
      "source": [
        "model_config = \"RF_cfg1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0vmnuVYssiu"
      },
      "outputs": [],
      "source": [
        "model_name = \"model_{}_{}\".format(feature_set, model_config)\n",
        "print(f\"Checking for existing model '{model_name}'\")\n",
        "model = load_model(model_name)\n",
        "if not model:\n",
        "    print(f\"model not found, creating new one\")\n",
        "    params = model_configs[model_config]\n",
        "\n",
        "    if model_config.startswith(\"LGBM\"):\n",
        "        model = LGBMRegressor(**params)\n",
        "    elif model_config.startswith(\"RF\"):\n",
        "        model = RandomForestRegressor(**params)\n",
        "    else:\n",
        "        model = XGBRegressor(**params)\n",
        "\n",
        "    # train on all of train and save the model so we don't have to train next time\n",
        "    spinner.start('Training model')\n",
        "    model.fit(training_data.filter(like='feature_', axis='columns'),\n",
        "              training_data[TARGET_COL])\n",
        "    print(f\"saving new model: {model_name}\")\n",
        "    save_model(model, model_name)\n",
        "    spinner.succeed()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn02Jeomssiu"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1OOvtJassiu"
      },
      "outputs": [],
      "source": [
        "print('Reading minimal features of validation and tournament data...')\n",
        "validation_data = pd.read_parquet('data/numerai_validation_data.parquet',\n",
        "                                  columns=read_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ywORulTssiv"
      },
      "outputs": [],
      "source": [
        "tournament_data = pd.read_parquet(f'data/tournament_data_{current_round}.parquet',\n",
        "                                  columns=read_columns)\n",
        "nans_per_col = tournament_data[tournament_data[\"data_type\"] == \"live\"].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBGve2BQssiv"
      },
      "outputs": [],
      "source": [
        "# check for nans and fill nans\n",
        "if nans_per_col.any():\n",
        "    total_rows = len(tournament_data[tournament_data[\"data_type\"] == \"live\"])\n",
        "    print(f\"Number of nans per column this week: {nans_per_col[nans_per_col > 0]}\")\n",
        "    print(f\"out of {total_rows} total rows\")\n",
        "    print(f\"filling nans with 0.5\")\n",
        "    tournament_data.loc[:, features].fillna(0.5, inplace=True)\n",
        "else:\n",
        "    print(\"No nans in the features this week!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_faYxj8Ossiv"
      },
      "outputs": [],
      "source": [
        "spinner.start('Predicting on validation and tournament data')\n",
        "# double check the feature that the model expects vs what is available to prevent our\n",
        "# pipeline from failing if Numerai adds more data and we don't have time to retrain!\n",
        "model_expected_features = model.booster_.feature_name()\n",
        "if set(model_expected_features) != set(features):\n",
        "    print(f\"New features are available! Might want to retrain model {model_name}.\")\n",
        "validation_data.loc[:, f\"preds_{model_name}\"] = model.predict(\n",
        "    validation_data.loc[:, model_expected_features])\n",
        "tournament_data.loc[:, f\"preds_{model_name}\"] = model.predict(\n",
        "    tournament_data.loc[:, model_expected_features])\n",
        "spinner.succeed()\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAhyH81Kssiv"
      },
      "outputs": [],
      "source": [
        "all_feature_corrs = training_data.groupby(ERA_COL).apply(\n",
        "    lambda era: era[features].corrwith(era[TARGET_COL])\n",
        ")\n",
        "riskiest_features = get_biggest_change_features(all_feature_corrs, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBi8riYIssiw"
      },
      "outputs": [],
      "source": [
        "spinner.start('Neutralizing to risky features')\n",
        "\n",
        "# neutralize our predictions to the riskiest features\n",
        "validation_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(\n",
        "    df=validation_data,\n",
        "    columns=[f\"preds_{model_name}\"],\n",
        "    neutralizers=riskiest_features,\n",
        "    proportion=1.0,\n",
        "    normalize=True,\n",
        "    era_col=ERA_COL\n",
        ")\n",
        "\n",
        "tournament_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(\n",
        "    df=tournament_data,\n",
        "    columns=[f\"preds_{model_name}\"],\n",
        "    neutralizers=riskiest_features,\n",
        "    proportion=1.0,\n",
        "    normalize=True,\n",
        "    era_col=ERA_COL\n",
        ")\n",
        "spinner.succeed()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqP4aoGxssiw"
      },
      "outputs": [],
      "source": [
        "current_round"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpqa8Thjssiw"
      },
      "outputs": [],
      "source": [
        "model_to_submit = f\"preds_{model_name}_neutral_riskiest_50\"\n",
        "\n",
        "# rename best model to \"prediction\" and rank from 0 to 1 to meet upload requirements\n",
        "validation_data[\"prediction\"] = validation_data[model_to_submit].rank(pct=True)\n",
        "tournament_data[\"prediction\"] = tournament_data[model_to_submit].rank(pct=True)\n",
        "validation_data[\"prediction\"].to_csv(f\"pred/validation_predictions_{model_name}_{current_round}.csv\")\n",
        "tournament_data[\"prediction\"].to_csv(f\"pred/tournament_predictions_{model_name}_{current_round}.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVbr3hOxssiw"
      },
      "outputs": [],
      "source": [
        "model_to_submit = f\"preds_{model_name}\"\n",
        "\n",
        "validation_data[\"prediction_w_risk\"] = validation_data[model_to_submit].rank(pct=True)\n",
        "tournament_data[\"prediction_w_risk\"] = tournament_data[model_to_submit].rank(pct=True)\n",
        "validation_data[\"prediction_w_risk\"].to_csv(f\"pred/validation_predictions_{model_name}_{current_round}.csv\")\n",
        "tournament_data[\"prediction_w_risk\"].to_csv(f\"pred/tournament_predictions_{model_name}_{current_round}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ft3MX7rssiw"
      },
      "outputs": [],
      "source": [
        "model_to_submit = f\"preds_{model_name}_neutral_riskiest_50\"\n",
        "\n",
        "# rename best model to \"prediction\" and rank from 0 to 1 to meet upload requirements\n",
        "validation_data[\"prediction\"] = validation_data[model_to_submit].rank(pct=True)\n",
        "tournament_data[\"prediction\"] = tournament_data[model_to_submit].rank(pct=True)\n",
        "validation_data[\"prediction\"].to_csv(f\"pred/validation_predictions_{model_name}_{current_round}.csv\")\n",
        "tournament_data[\"prediction\"].to_csv(f\"pred/tournament_predictions_{model_name}_{current_round}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPG4LoOtssix"
      },
      "outputs": [],
      "source": [
        "validation_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6gfao_7ssi0"
      },
      "outputs": [],
      "source": [
        "validation_data[[\"prediction_w_risk\", \"prediction\", \"preds_model_medium_LGBM_cfg1\", \"preds_model_medium_LGBM_cfg1_neutral_riskiest_50\", \"target_nomi_20\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-38cPwpZssi0"
      },
      "outputs": [],
      "source": [
        "validation_data[\"target_nomi_20\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zAp0WzIssi0"
      },
      "source": [
        "## Regression to Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt7RPLEGssi0"
      },
      "outputs": [],
      "source": [
        "def val2class(x):\n",
        "    if 0 <= x < 0.125:\n",
        "        return 0\n",
        "    elif 0.125 <= x < 0.375:\n",
        "        return 1\n",
        "    elif 0.375 <= x < 0.625:\n",
        "        return 2\n",
        "    elif 0.625 <= x < 0.875:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyaH1OtAssi1"
      },
      "outputs": [],
      "source": [
        "# model as multiclass classification\n",
        "y_class = validation_data[\"target_nomi_20\"].apply(val2class).values.reshape(-1, 1)\n",
        "y_pred = validation_data[\"prediction_w_risk\"].apply(val2class).values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L2PyaSUssi1"
      },
      "outputs": [],
      "source": [
        "print(y_class.shape)\n",
        "print(y_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDyDfSaGssi1"
      },
      "outputs": [],
      "source": [
        "ohe = OneHotEncoder()\n",
        "y_class = ohe.fit_transform(y_class).toarray()\n",
        "y_pred = ohe.transform(y_pred).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGt3zGDossi1"
      },
      "outputs": [],
      "source": [
        "print(y_class.shape)\n",
        "print(y_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0iAY8FOssi1"
      },
      "outputs": [],
      "source": [
        "roc_auc_score(y_class, y_pred, multi_class=\"ovr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7100IBKVssi2"
      },
      "source": [
        "## Train classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLeu44Oassi2"
      },
      "outputs": [],
      "source": [
        "model_clf_configs = {\n",
        "    \"LGBM_cfg1\": {\n",
        "        \"n_estimators\": 2000,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"max_depth\": 5,\n",
        "        \"num_leaves\": 2 ** 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "    \"LGBM_cfg2\": {\n",
        "        \"n_estimators\": 3000,\n",
        "        \"learning_rate\": 0.005,\n",
        "        \"max_depth\": 5,\n",
        "        \"num_leaves\": 2 ** 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5WqeArlssi2"
      },
      "outputs": [],
      "source": [
        "model_clf_config = \"LGBM_cfg1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l54lvpOBssi2"
      },
      "outputs": [],
      "source": [
        "model_name = \"model_clf_{}_{}\".format(feature_set, model_clf_config)\n",
        "print(f\"Checking for existing model '{model_name}'\")\n",
        "model = load_model(model_name)\n",
        "if not model:\n",
        "    print(f\"model not found, creating new one\")\n",
        "    params = model_clf_configs[model_clf_config]\n",
        "\n",
        "    if model_clf_config.startswith(\"LGBM\"):\n",
        "        model = LGBMClassifier(**params)\n",
        "    else:\n",
        "        print(\"Not support\")\n",
        "    # elif model_config.startswith(\"RF\"):\n",
        "    #     model = RandomForestRegressor(**params)\n",
        "    # else:\n",
        "    #     model = XGBRegressor(**params)\n",
        "\n",
        "    # train on all of train and save the model so we don't have to train next time\n",
        "    spinner.start('Training model')\n",
        "    y = training_data[TARGET_COL].values.reshape(-1, 1)\n",
        "    ohe = OneHotEncoder()\n",
        "    y = ohe.fit_transform(y).toarray()\n",
        "    \n",
        "    model = OneVsRestClassifier(model).fit(training_data.filter(like='feature_', axis='columns'), y)#.predict(X)\n",
        "    # model.fit(training_data.filter(like='feature_', axis='columns'), y)\n",
        "    print(f\"saving new model: {model_name}\")\n",
        "    save_model(model, model_name)\n",
        "    spinner.succeed()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb_3XV7ossi2"
      },
      "outputs": [],
      "source": [
        "y = validation_data[TARGET_COL].values.reshape(-1, 1)\n",
        "ohe = OneHotEncoder()\n",
        "y = ohe.fit_transform(y).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4uQMhu1ssi3"
      },
      "outputs": [],
      "source": [
        "# model_expected_features = model.booster_.feature_name()\n",
        "y_pred = model.predict(validation_data.filter(like='feature_', axis='columns'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMmEVS3vssi3"
      },
      "outputs": [],
      "source": [
        "roc_auc_score(y, y_pred, multi_class=\"ovr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i99dBqumssi3"
      },
      "outputs": [],
      "source": [
        "spinner.start('Reading example validation predictions')\n",
        "# validation_preds = pd.read_parquet(f\"pred/validation_predictions_{model_name}_{current_round}.csv\")\n",
        "validation_preds = pd.read_csv(f\"pred/validation_predictions_{model_name}_{current_round}.csv\")\n",
        "validation_data[EXAMPLE_PREDS_COL] = validation_preds[\"prediction\"]\n",
        "spinner.succeed()\n",
        "\n",
        "# get some stats about each of our models to compare...\n",
        "# fast_mode=True so that we skip some of the stats that are slower to calculate\n",
        "# validation_stats = validation_metrics(validation_data, [model_to_submit], example_col=EXAMPLE_PREDS_COL, fast_mode=True)\n",
        "# print(validation_stats[[\"mean\", \"sharpe\"]].to_markdown())\n",
        "# print(validation_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpG_BpYassi3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7npvsVQEssi3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aP20Pnissi3"
      },
      "source": [
        "## Advanced Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V01ofYGLssi4"
      },
      "outputs": [],
      "source": [
        "advanced_model_configs = {\n",
        "    \"LGBM_cfg1\": {\n",
        "        \"n_estimators\": 2000,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"max_depth\": 5,\n",
        "        \"num_leaves\": 2 ** 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "    \"LGBM_cfg2\": {\n",
        "        \"n_estimators\": 3000,\n",
        "        \"learning_rate\": 0.005,\n",
        "        \"max_depth\": 5,\n",
        "        \"num_leaves\": 2 ** 5,\n",
        "        \"colsample_bytree\": 0.1\n",
        "    },\n",
        "    \"RF_cfg1\": {\n",
        "        \"n_estimators\": 1000,\n",
        "        \"criterion\": \"squared_error\",\n",
        "        \"max_depth\": 5,\n",
        "        \"min_samples_leaf\": 5\n",
        "    },\n",
        "    \"RF_cfg2\": {\n",
        "        \"n_estimators\": 2000,\n",
        "        \"criterion\": \"squared_error\",\n",
        "        \"max_depth\": 3,\n",
        "        \"min_samples_leaf\": 5\n",
        "    },\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-06XGTWssi4"
      },
      "outputs": [],
      "source": [
        "advanced_training_configs = {\n",
        "    \"FEATURE_SET\": \"medium\",\n",
        "    \"MODEL_CONFIG\": \"LGBM_cfg1\",\n",
        "    \"downsample_cross_val\": 20,\n",
        "    \"downsample_full_train\": 1,\n",
        "    \"model_selection_loop\": True,\n",
        "    \"model_config_name\": \"advanced_example_model\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVFmb4Knssi4"
      },
      "outputs": [],
      "source": [
        "model_config_name = \"LGBM_cfg1\"\n",
        "model_params = advanced_model_configs[model_config_name]\n",
        "\n",
        "print(\"Entering model selection loop.  This may take awhile.\")\n",
        "if advanced_training_configs[\"model_selection_loop\"]:\n",
        "    model_config = {}\n",
        "    print('downloading training_data')\n",
        "\n",
        "    # keep track of some prediction columns\n",
        "    ensemble_cols = set()\n",
        "    pred_cols = set()\n",
        "\n",
        "    # pick some targets to use\n",
        "    possible_targets = [c for c in training_data.columns if c.startswith(\"target_\")]\n",
        "    # randomly pick a handful of targets\n",
        "    # this can be vastly improved\n",
        "    targets = [\"target_nomi_20\"]\n",
        "\n",
        "    # all the possible features to train on\n",
        "    feature_cols = [c for c in training_data if c.startswith(\"feature_\")]\n",
        "\n",
        "    \"\"\" do cross val to get out of sample training preds\"\"\"\n",
        "    cv = 3\n",
        "    train_test_zip = get_time_series_cross_val_splits(training_data, cv=cv, embargo=12)\n",
        "    # get out of sample training preds via embargoed time series cross validation\n",
        "    # optionally downsample training data to speed up this section.\n",
        "    print(\"entering time series cross validation loop\")\n",
        "    for split, train_test_split in enumerate(train_test_zip):\n",
        "        gc.collect()\n",
        "        print(f\"doing split {split+1} out of {cv}\")\n",
        "        train_split, test_split = train_test_split\n",
        "        train_split_index = training_data[ERA_COL].isin(train_split)\n",
        "        test_split_index = training_data[ERA_COL].isin(test_split)\n",
        "        downsampled_train_split_index = train_split_index[train_split_index].index[::advanced_training_configs[\"downsample_cross_val\"]]\n",
        "\n",
        "        # getting the per era correlation of each feature vs the primary target across the training split\n",
        "        print(\"getting feature correlations over time and identifying riskiest features\")\n",
        "        all_feature_corrs_split = training_data.loc[downsampled_train_split_index, :].groupby(ERA_COL).apply(\n",
        "            lambda d: d[feature_cols].corrwith(d[TARGET_COL]))\n",
        "        # find the riskiest features by comparing their correlation vs the target in half 1 and half 2 of training data\n",
        "        # there are probably more clever ways to do this\n",
        "        riskiest_features_split = get_biggest_change_features(all_feature_corrs_split, 50)\n",
        "\n",
        "        print(f\"entering model training loop for split {split+1}\")\n",
        "        for target in targets:\n",
        "            model_name = f\"model_{target}\"\n",
        "            print(f\"model: {model_name}\")\n",
        "\n",
        "            # train a model on the training split (and save it for future use)\n",
        "            downsample_cross_val = advanced_training_configs[\"downsample_cross_val\"]\n",
        "            split_model_name = f\"model_{target}_split{split+1}cv{cv}downsample{downsample_cross_val}\"\n",
        "            split_model = load_model(split_model_name)\n",
        "            if not split_model:\n",
        "                print(f\"training model: {model_name}\")\n",
        "                split_model = LGBMRegressor(**model_params)\n",
        "                split_model.fit(training_data.loc[downsampled_train_split_index, feature_cols],\n",
        "                                training_data.loc[downsampled_train_split_index,\n",
        "                                                  [target]])\n",
        "                save_model(split_model, split_model_name)\n",
        "            # now we can predict on the test part of the split\n",
        "            model_expected_features = split_model.booster_.feature_name()\n",
        "            if set(model_expected_features) != set(feature_cols):\n",
        "                print(f\"New features are available! Might want to retrain model {split_model_name}.\")\n",
        "            print(f\"predicting {model_name}\")\n",
        "            training_data.loc[test_split_index, f\"preds_{model_name}\"] = \\\n",
        "                split_model.predict(training_data.loc[test_split_index, model_expected_features])\n",
        "\n",
        "            # do neutralization\n",
        "            print(\"doing neutralization to riskiest features\")\n",
        "            training_data.loc[test_split_index, f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(\n",
        "                df=training_data.loc[test_split_index, :],\n",
        "                columns=[f\"preds_{model_name}\"],\n",
        "                neutralizers=riskiest_features_split,\n",
        "                proportion=1.0,\n",
        "                normalize=True,\n",
        "                era_col=ERA_COL)[f\"preds_{model_name}\"]\n",
        "\n",
        "            # remember that we made all of these different pred columns\n",
        "            pred_cols.add(f\"preds_{model_name}\")\n",
        "            pred_cols.add(f\"preds_{model_name}_neutral_riskiest_50\")\n",
        "\n",
        "        print(\"creating ensembles\")\n",
        "        # ranking per era for all of our pred cols so we can combine safely on the same scales\n",
        "        training_data[list(pred_cols)] = training_data.groupby(ERA_COL).apply(\n",
        "            lambda d: d[list(pred_cols)].rank(pct=True))\n",
        "        # do ensembles\n",
        "        training_data[\"ensemble_neutral_riskiest_50\"] = sum(\n",
        "            [training_data[pred_col] for pred_col in pred_cols if pred_col.endswith(\"neutral_riskiest_50\")]).rank(\n",
        "            pct=True)\n",
        "        training_data[\"ensemble_not_neutral\"] = sum(\n",
        "            [training_data[pred_col] for pred_col in pred_cols if \"neutral\" not in pred_col]).rank(pct=True)\n",
        "        training_data[\"ensemble_all\"] = sum([training_data[pred_col] for pred_col in pred_cols]).rank(pct=True)\n",
        "\n",
        "        ensemble_cols.add(\"ensemble_neutral_riskiest_50\")\n",
        "        ensemble_cols.add(\"ensemble_not_neutral\")\n",
        "        ensemble_cols.add(\"ensemble_all\")\n",
        "\n",
        "    \"\"\" Now get some stats and pick our favorite model\"\"\"\n",
        "    print(\"gathering validation metrics for out of sample training results\")\n",
        "    all_model_cols = list(pred_cols) + list(ensemble_cols)\n",
        "    # use example_col preds_model_target as an estimates since no example preds provided for training\n",
        "    # fast_mode=True so that we skip some of the stats that are slower to calculate\n",
        "    training_stats = validation_metrics(training_data, all_model_cols, example_col=\"preds_model_target\",\n",
        "                                        fast_mode=True)\n",
        "    print(training_stats[[\"mean\", \"sharpe\"]].sort_values(by=\"sharpe\", ascending=False).to_markdown())\n",
        "\n",
        "    # pick the model that has the highest correlation sharpe\n",
        "    best_pred_col = training_stats.sort_values(by=\"sharpe\", ascending=False).head(1).index[0]\n",
        "    print(f\"selecting model {best_pred_col} as our highest sharpe model in validation\")\n",
        "\n",
        "    \"\"\" Now do a full train\"\"\"\n",
        "    print(\"entering full training section\")\n",
        "    # getting the per era correlation of each feature vs the target across all of training data\n",
        "    print(\"getting feature correlations with target and identifying riskiest features\")\n",
        "    all_feature_corrs = training_data.groupby(ERA_COL).apply(\n",
        "        lambda d: d[feature_cols].corrwith(d[TARGET_COL]))\n",
        "    # find the riskiest features by comparing their correlation vs the target in half 1 and half 2 of training data\n",
        "    riskiest_features = get_biggest_change_features(all_feature_corrs, 50)\n",
        "\n",
        "    for target in targets:\n",
        "        gc.collect()\n",
        "        downsample_full_train = advanced_training_configs[\"downsample_full_train\"]\n",
        "        model_name = f\"model_{target}_downsample{downsample_full_train}\"\n",
        "        model = load_model(model_name)\n",
        "        if not model:\n",
        "            print(f\"training {model_name}\")\n",
        "            model = LGBMRegressor(**model_params)\n",
        "            # train on all of train, predict on val, predict on tournament\n",
        "            model.fit(training_data.iloc[::advanced_training_configs[\"downsample_full_train\"]].loc[:, feature_cols],\n",
        "                      training_data.iloc[::advanced_training_configs[\"downsample_full_train\"]][target])\n",
        "            save_model(model, model_name)\n",
        "        gc.collect()\n",
        "\n",
        "    model_config[\"feature_cols\"] = feature_cols\n",
        "    model_config[\"targets\"] = targets\n",
        "    model_config[\"best_pred_col\"] = best_pred_col\n",
        "    model_config[\"riskiest_features\"] = riskiest_features\n",
        "    print(f\"saving model config for {model_config_name}\")\n",
        "    save_model_config(model_config, model_config_name)\n",
        "else:\n",
        "    # load model config from previous model selection loop\n",
        "    print(f\"loading model config for {model_config_name}\")\n",
        "    model_config = load_model_config(model_config_name)\n",
        "    feature_cols = model_config[\"feature_cols\"]\n",
        "    targets = model_config[\"targets\"]\n",
        "    best_pred_col = model_config[\"best_pred_col\"]\n",
        "    riskiest_features = model_config[\"riskiest_features\"]\n",
        "\n",
        "\n",
        "\"\"\" Things that we always do even if we've already trained \"\"\"\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTn-PF2Qssi6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "ccdbd9f1158aa7f65b3bacd2e1517888ef68beedcf7918a09b2f53f24aa4d343"
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}